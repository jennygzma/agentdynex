[
  {
    "problem": "Agents do not have a mechanism to execute sequences of tasks, causing inconsistent logistics.",
    "problem_example": "In the school president campaign example, students are interfering with the debate and talking too much, not respecting the directive of not being able to speak when the candidates are speaking. Additionally, there is no way for students to vote in a private booth because no one is counting the votes. ",
    "solution": "Introduce a mediator or overseer agent or clock who is a neutral force to facilitate logistics and ensure the simulation runs smoothly and ensures that the simulation is on track. ",
    "solution_example": "In the school president campaign scenario, introduce a mediator agent who facilitates the debates (does not allow candidates to speak more than once, only allows voters to ask ONE question and candidates to respond once), and guides the students to a voting booth after each debate and counts the votes. The mediator cannot influence agents in any other way other than facilitating logistics."
  },
  {
    "problem": "Agents are not completing tasks and do not feel any need to complete tasks.",
    "problem_example": "In a scenario simulating prom, despite prom being on the corner and some agents having no dates, they show no urgency in trying to find a date.",
    "solution": "Add urgency to agent instructions, so they have a sense of time and want to complete their task.",
    "solution_example": "In the scenario simulating finding prom dates, add 'Feel increasing anxiety about not having a date as time passes' and 'Make a decision within a couple rounds of receiving a proposal' to everyone's directives."
  },
  {
    "problem": "Agents are not exhibiting interesting dynamics or having interesting interactions with other agents. ",
    "problem_example": "In the scenario simulating prom, agents pair up to the first person they see even if they are not a good match.",
    "solution": "Add stakes to the agent personalities.",
    "solution_example": "In the scenario simulating finding prom dates, add romantic interests to the agent bios, if someone is shy say that they are EXTREMELY SHY AND DEATHLY SCARED OF SOCIAL INTERACTION, and ACCENTUATE that it will be EXTREMELY EMBARRASSING if agents do no find a date to prom OR go with someone they don’t want to go to. "
  },
  {
    "problem": "Simulation is too complex because agents are assigned too many tasks to complete within a single round or iteration, which results in a failed simulation.",
    "problem_example": "If simulating a classroom late policy made by a professor (where a professor assigns work to students and enforces a penalty for late submissions), a simulation that has 10 homework problems in a single assignment might take too long to run (if the simulation has multiple assignments for the students to complete then having each assignment be very lengthy) so students might lose track of the simulation goal or the simulation might crash because it exceed a certain run time.",
    "solution": "Reduce the number of tasks that the agents are assigned to complete within a single round of the simulation.",
    "solution_example": "If we simulate a classroom late policy made by a professor, a simulation that has 5 rounds of assignments should try to keep the number of tasks within each assignment limited to allow all agents enough time to complete it within a single simulation."
  },
  {
    "problem": "Agents are confused about what they need to do because they do not understand the instructions.",
    "problem_example": "If simulating a classroom late policy made by a professor (where a professor assigns work to students and enforces a penalty for late submissions), the professor has not specified the details of the assignments that the students need to complete and/or has not told students how they should “submit” the assignment. ",
    "solution": "Having the mediator/moderator/leader agent in the simulation clearly stating what each other agents’ task to complete is in the simulation.",
    "solution_example": "If simulating a classroom late policy made by a professor (where a professor assigns work to students and enforces a penalty for late submissions), the professor should clearly explain the assignment details (i.e., “a short paragraph on how AI is affecting learning ”) and how the students should submit it (i.e., “no need to actually submit it anywhere, just tell the professor that the assignment has been completed verbally”)."
  },
  {
    "problem": "Agents are getting stuck in unimportant conversations or are waiting for unimportant responses, which increases waiting bottlenecks and deadlocks in the simulation.",
    "problem_example": "If simulating a classroom late policy made by a professor (where a professor is supposed to assign work to students and enforce a penalty for late submissions), then if the professor forgets to assign the assignments to the students or forgets to announce the late policy, then students will keep waiting around for the instructions and the simulation would never progress, causing it to fail.",
    "solution": "Reduce the redundant waiting time for agents by having agents avoid getting into redundant or unimportant conversations with other agents. ",
    "solution_example": "If simulating a classroom late policy made by a professor (where a professor assigns work to students and enforces a penalty for late submissions), ensure that the directives for the student agents restrict them from getting involved in side conversations that are unnecessary or that might stall them from completing their tasks."
  },
  {
    "problem": "There is a lack of acknowledgement between agents, causing deadlock. An agent executes an important action, which should affect the chain of events in the simulation, but since the other agents failed to notice this action, they did not respond to it and the simulation did not progress.",
    "problem_example": "If the simulation is about simulating the public goods game with some players and a mediator, where players contribute some value of money to a common pot to see if people will cooperate for the benefit of the group, then an example of this error might look like a player has contributed something to the common pot, but the mediator did not notice that this player has contributed something, and so the mediator is still waiting for them to contribute, and the players are waiting for the mediator to conclude the round, and the simulation ends up getting stuck in an indefinite waiting state (deadlock), which causes it to fail.",
    "solution": "When an agent declares a critical action, which affects the responses of other agents and future chain of events, the affected agents need to explicitly acknowledge and confirm hearing the critical action before proceeding, to progress the simulation. Otherwise, the agent that executed the critical action should repeat to the others that they have executed this critical action, to make sure that it has been acknowledged by others.",
    "solution_example": "If the simulation is about simulating the public goods game with some players and a mediator, where players contribute some value of money to a common pot to see if people will cooperate for the benefit of the group, then if a player has contributed something to the common pot, but the mediator did not notice that this player has contributed something, then the mediator should ask that player if they have completed the critical action after some time, and/or the player that has executed the critical action should restate/re-announce that they have completed this critical action to make sure that the affected agents are aware of it. "
  },
  {
    "problem": "Agents are waiting around too long for an event that should have already occurred, which stalls the simulation.",
    "problem_example": "If simulating a classroom late policy made by a professor (where a professor is supposed to assign work to students and enforce a penalty for late submissions), then if the professor forgets to assign the assignments to the students or forgets to announce the late policy, then students will keep waiting around for the instructions and the simulation would never progress, causing it to fail.",
    "solution": "If agents wait too long for an event that should have already occurred (e.g., round start), allow them to prompt the proper agent (i.e., mediator) or retry the trigger.",
    "solution_example": "For example, if simulating a classroom late policy made by a professor (where a professor is supposed to assign work to students and enforce a penalty for late submissions), if the professor forgets to assign the assignments to the students, then students should ask the professor what the assignments are they they have to complete."
  },
  {
    "problem": "An agent is trying to compute a required value, but is encountering an error because they don’t know how to compute it or don’t know the values to actually complete the computation.",
    "problem_example": "If the simulation is about simulating the public goods game with some players and a mediator, where players contribute some value of money to a common pot to see if people will cooperate for the benefit of the group, then an example of this error might look like the mediator has received all of the contributions from the players and is encountering an error when trying to compute the total and the distribution amount for each player, resulting in the mediator either asking the human for help or encountering an EOF error, or not remembering which values to use for the computation.",
    "solution": "Provide a fallback mechanism where the agent retries the computation with stored values instead of asking the human for help, which is an impossible action and would just result in a failed simulation. Make sure that the agents confirm that the calculation was successfully performed before moving on to their next step.",
    "solution_example": "If the simulation is about simulating the public goods game with some players and a mediator, where players contribute some value of money to a common pot to see if people will cooperate for the benefit of the group, then an example of this error might look like the mediator has received all of the contr"
  },
  {
    "problem": "An agent is requesting human input for a task when they cannot speak to a human.",
    "problem_example": "If the simulation is about simulating the public goods game with some players and a mediator, where players contribute some value of money to a common pot to see if people will cooperate for the benefit of the group, then an example of this error might look like the player does not know how much they should contribute or the mediator does not know how to redistribute the players’ contributions and so they attempt to consult the human for information or advice or direction, which is an impossible action because they cannot consult a human in the simulation, and so the simulation fails.",
    "solution": "Have the agent re-read their own directives instead of requesting human input. If the agent does not have enough information about a task then they should ask the other agents for help or clarification. Ensure by all means that the agent is not requesting any external (aka human) help or seeking external resources (which would just result in EOF errors), and instead relies on their predefined fallback mechanisms.",
    "solution_example": "If the simulation is about simulating the public goods game with some players and a mediator, where players contribute some value of money to a common pot to see if people will cooperate for the benefit of the group, then if the player does not know how much they should contribute or the mediator does not know how to redistribute the players’ contributions then instead of attempting to consult the human for information or advice or direction, they should just either consult their own directives again, ask the other agents for information/advice/direction, or just make their best guess based off their current understanding."
  },
  {
    "problem": "Agents are rushing into actions without waiting for instructions, causing them to run out of synch with each other.",
    "problem_example": "If simulating a classroom late policy made by a professor (where a professor is supposed to assign work to students and enforce a penalty for late submissions), then an example of this error might look like all the students are already going off doing their own thing, starting conversations with the others, etc. etc. before the professor even announces what their tasks are to complete. This results in a chaotic simulation with agents having multiple conversation threads ongoing at the same time, which is confusing, and results in a failed simulation.",
    "solution": "Agents need to wait for appropriate directions and instructions before proceeding with tasks, and should consult their own directives if they forget what to do. ",
    "solution_example": "If simulating a classroom late policy made by a professor (where a professor is supposed to assign work to students and enforce a penalty for late submissions), then students need to wait to hear the professor’s announcement and directives first before starting their own conversations with others, to ensure that they are not starting any redundant conversations that might distract or confuse them from the tasks that they’ve been assigned to complete."
  },
  {
    "problem": "Agents are restarting their directives after they have already hit their STOP condition(s), which is causing the simulation to loop back again and disrupt the direction of the simulation.",
    "problem_example": "If simulating a classroom late policy made by a professor (where a professor is supposed to assign work to students and enforce a penalty for late submissions), then if we have an example where one student has completed and submitted all the assignments (therefore hitting their STOP condition), but the other students are still working on the assignment, then the student who has hit their STOP condition restarts their directives, and basically starts redoing the assignments that have been assigned by the professor, which messes up with the simulation progress.",
    "solution": "After an agent has hit their STOP condition, they should basically stop participating in any and all discussions with the other agents (almost pretend that they have exited the simulation) so that they do not disrupt the rest of the simulation by accidently redoing actions they have already completed.",
    "solution_example": "If simulating a classroom late policy made by a professor (where a professor is supposed to assign work to students and enforce a penalty for late submissions), then if we have an example where one student has completed and submitted all the assignments (therefore hitting their STOP condition), but the other students are still working on the assignment, then the student who has hit their STOP condition should just basically stop participating at all in the simulation at that point so that they don’t interfere with other agents completing their tasks."
  }
]
